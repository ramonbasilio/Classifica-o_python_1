{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto do algoritmo MultinomialNB: 85.714 %\n",
      "Taxa de acerto do algoritmo AdaBoost: 85.714 %\n",
      "Algoritmo vencedor: Modelo AdaBoost\n",
      "Taxa de acertos do algoritmo Modelo AdaBoost com dados de validacao: 62.5 %\n",
      "\n",
      "Taxa de acerto com algoritmo base: 62.5 %\n",
      "Total de teste: 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "dados = pd.read_csv('busca2.csv')\n",
    "\n",
    "X_df = dados[['home','busca','logado']]\n",
    "Y_df = dados['comprou']\n",
    "\n",
    "Xdummies_df = pd.get_dummies(X_df)\n",
    "Ydummies_df = Y_df\n",
    "\n",
    "X = Xdummies_df.values\n",
    "Y = Ydummies_df.values\n",
    "\n",
    "#----------------------------------------------------------------------------------------#\n",
    "\n",
    "# 80% para treino e 10% para teste e 10% para validação\n",
    "porcentagem_treino = 0.8\n",
    "porcentagem_teste = 0.1\n",
    "\n",
    "# 1000 elementos\n",
    "total_elementos = len(X)\n",
    "\n",
    "# 800 de treino, 100 teste e 100 de validação\n",
    "elementos_treino = int(porcentagem_treino * total_elementos)\n",
    "elementos_teste = int(porcentagem_teste * total_elementos)\n",
    "elementos_validacao = total_elementos - elementos_treino - elementos_teste\n",
    "\n",
    "# 900 > auxiliar\n",
    "fim_do_teste = elementos_teste + elementos_treino \n",
    "\n",
    "# 0 até o 799 TREINO\n",
    "treino_dados = X[0:elementos_treino]\n",
    "treino_marcacoes = Y[0:elementos_treino]\n",
    "\n",
    "# 800 até 899 TESTE\n",
    "teste_dados = X[elementos_treino:fim_do_teste]\n",
    "teste_marcacoes = Y[elementos_treino:fim_do_teste]\n",
    "\n",
    "# 900 até 999 VALIDAÇÃO\n",
    "validacao_dados = X[fim_do_teste:]\n",
    "validacao_marcacoes = Y[fim_do_teste:]\n",
    "\n",
    "#----------------------------------------------------------------------------------------#\n",
    "\n",
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes):\n",
    "    modelo.fit(treino_dados, treino_marcacoes) #treino do algoritmo\n",
    "    resultado = modelo.predict(teste_dados) #resultado com as predições (array com 0 e 1)\n",
    "    taxa_de_acerto = round((accuracy_score(resultado, teste_marcacoes)*100),3)\n",
    "    '''\n",
    "    acertos = (resultado == teste_marcacoes) #acertos, isto é, array com trues e falses em comparação com o resultado do\n",
    "                                             #predict e do teste marcações       \n",
    "    total_de_acertos = sum(acertos) #total de trues (acertos do algoritmo)\n",
    "    total_de_elementos = len(teste_dados) #total de elementos que é igual a 100\n",
    "    taxa_de_acertos = 100.0 * (total_de_acertos / total_de_elementos) #porcentagem de acertos do algoritmo\n",
    "    '''\n",
    "    \n",
    "    mensagem = 'Taxa de acerto do algoritmo {0}: {1} %'.format(nome, taxa_de_acerto) \n",
    "    print(mensagem) #mensagem de saida com o nome do algoritmo e a taxa de acerto\n",
    "    return taxa_de_acerto #retorno da função com a taxa de acertos\n",
    "\n",
    "#----------------------------------------------------------------------------------------#\n",
    "\n",
    "modelo_MultinomialNB = MultinomialNB()\n",
    "resultado_MultinomialNB = fit_and_predict('MultinomialNB',\n",
    "                                          modelo_MultinomialNB,\n",
    "                                          treino_dados, \n",
    "                                          treino_marcacoes, \n",
    "                                          teste_dados, \n",
    "                                          teste_marcacoes)\n",
    "\n",
    "\n",
    "modelo_AdaBoost = AdaBoostClassifier()\n",
    "resultado_AdaBoost = fit_and_predict('AdaBoost',\n",
    "                                     modelo_AdaBoost,\n",
    "                                     treino_dados, \n",
    "                                     treino_marcacoes, \n",
    "                                     teste_dados, \n",
    "                                     teste_marcacoes)\n",
    "\n",
    "#----------------------------------------------------------------------------------------#\n",
    "\n",
    "if resultado_MultinomialNB > resultado_AdaBoost:\n",
    "    vencedor = modelo_MultinomialNB\n",
    "    nome_do_vencendor = 'Modelo MultinomialNB'\n",
    "    \n",
    "else:\n",
    "        vencedor = modelo_AdaBoost\n",
    "        nome_do_vencendor = 'Modelo AdaBoost'\n",
    "        \n",
    "print('Algoritmo vencedor: {}'.format(nome_do_vencendor))\n",
    "          \n",
    "resultado = vencedor.predict(validacao_dados)\n",
    "taxa_de_acerto = accuracy_score(validacao_marcacoes, resultado)\n",
    "\n",
    "'''\n",
    "acertos = (resultado == validacao_marcacoes)\n",
    "total_acertos = sum(acertos)\n",
    "total_de_testes = len(validacao_marcacoes)\n",
    "\n",
    "taxa_de_acertos = 100.0 * (total_acertos / total_de_testes)\n",
    "'''\n",
    "\n",
    "mensagem = 'Taxa de acertos do algoritmo {0} com dados de validacao: {1} %\\n'.format(nome_do_vencendor, taxa_de_acerto*100)\n",
    "print(mensagem)\n",
    "\n",
    "#----------------------------------------------------------------------------------------#\n",
    "\n",
    "#validação do teste que chuta sempre 1 - TESTE BASE\n",
    "acertos = max(Counter(validacao_marcacoes).values())\n",
    "total_de_elementos = len(validacao_dados)\n",
    "taxa_de_acerto_base = 100.0 * (acertos / total_de_elementos)\n",
    "\n",
    "print(\"Taxa de acerto com algoritmo base: {} %\".format(taxa_de_acerto_base))\n",
    "\n",
    "total_de_elementos = len(validacao_dados)\n",
    "print(\"Total de teste: %d\" % total_de_elementos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
